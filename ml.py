import streamlit as st
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import plotly.express as px
import plotly.graph_objects as go
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, learning_curve
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.impute import SimpleImputer
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
#from xgboost import XGBRegressor
from sklearn.metrics import mean_squared_error, r2_score
# Page pour traitement des valeurs manquantes et outliers
from scipy.stats import zscore

from streamlit_extras.stylable_container import stylable_container


# Mod√®les avec hyperparam√®tres pour optimisation
MODELS_WITH_PARAMS = {
    "Linear Regression": (LinearRegression(), {}),
    "Ridge Regression": (Ridge(), {"model__alpha": [0.1, 1.0, 10]}),
    "Lasso Regression": (Lasso(), {"model__alpha": [0.1, 1.0, 10]}),
    "Elastic Net": (ElasticNet(), {"model__alpha": [0.1, 1.0, 10], "model__l1_ratio": [0.2, 0.5, 0.8]}),
    "Random Forest": (RandomForestRegressor(), {"model__n_estimators": [100, 200], "model__max_depth": [5, 10]}),
    "Gradient Boosting": (GradientBoostingRegressor(), {"model__n_estimators": [100, 200], "model__learning_rate": [0.01, 0.1]})
    #"XGBoost": (XGBRegressor(), {"model__n_estimators": [100, 200], "model__learning_rate": [0.01, 0.1]}),
}


# Variable globale pour stocker la base pr√©trait√©e
if "processed_data" not in st.session_state:
    st.session_state.processed_data = None


# Page de preprocessing

def preprocessing_page():
    st.title("Pr√©sentation des donn√©es")
    uploaded_file = st.file_uploader("Chargez un fichier CSV", type="csv")
    if uploaded_file is not None:
        df = pd.read_csv(uploaded_file)
        st.session_state.original_data = df  # Sauvegarde des donn√©es brutes
        st.markdown("**1. Aper√ßu des donn√©es**")
        n_bins = st.number_input(label = "Choisissez le nombre de lignes √† afficher",min_value = 5, value = 5)
        st.write(df.head(n_bins))
        st.write("La base de donn√©es contient :", df.shape[0],"lignes et", df.shape[1], "colonnes (variables).")
        st.markdown("**2. Type de variables**")
        # Pr√©parer un DataFrame pour afficher les noms et types de variables
        df_types = pd.DataFrame({"Variables": df.dtypes.index, "Type": df.dtypes.values}).reset_index(drop=True)
        n_bins2 = st.number_input(label = "Choisissez le nombre de variables",min_value = 5, value = 5)
        st.table(df_types.head(n_bins2))
        st.markdown("**3. Valeurs manquantes et doublons**")
        df_types2 = pd.DataFrame({"Variables": df.columns, "Nombre de valeurs manquantes": df.isnull().sum().values}).reset_index(drop=True)  
        n_bins3   = st.number_input(label = "Nombre de variables √† afficher", min_value = 5, value = 5)
        st.table(df_types2.head(n_bins3))
        st.write("Nombre de doublons :", df.duplicated().sum())
        st.markdown("**4. Statistiques descriptives**")
        st.write("Analyses descriptives des variables quantitatives:", df.describe())

        


def missing_values_page():
    st.title("Valeurs manquantes et outliers")
    
    if "original_data" in st.session_state:
        df = st.session_state.original_data.copy()
        
        st.markdown(
            """<div style="text-align: justify;">
            Cette section analyse les valeurs manquantes et les valeurs extr√™mes et propose des pipelines distincts pour le traitement des variables qualitatives et quantitatives.
            </div>""",
            unsafe_allow_html=True
        )
        
        # Analyse des valeurs manquantes
        st.markdown("### Analyse des valeurs manquantes")
        missing_percent = (df.isnull().sum() / len(df)) * 100
        missing_percent_df = missing_percent.reset_index()
        missing_percent_df.columns = ["Variables", "Pourcentage"]
        
        fig = px.bar(
            missing_percent_df,
            x="Variables",
            y="Pourcentage",
            title="Pourcentage de valeurs manquantes par variable",
            labels={"Pourcentage": "Pourcentage", "Variables": "Variables"},
            color="Pourcentage",
            color_continuous_scale="Viridis"
        )
        fig.update_layout(xaxis_tickangle=45, height=600)
        st.plotly_chart(fig)
        
        # Visualisation des valeurs aberrantes
        st.markdown("### Analyse des valeurs aberrantes")
        quantitative_vars = df.select_dtypes(include=["number"]).columns.tolist()
        
        if quantitative_vars:
            var_selected = st.selectbox("Choisir une variable quantitative", quantitative_vars)
            st.markdown("**Box-plot des valeurs**")
            fig_boxplot = px.box(df, y=var_selected, title=f"Box-plot pour {var_selected}")
            st.plotly_chart(fig_boxplot)
        else:
            st.info("Aucune variable quantitative d√©tect√©e pour l'analyse des valeurs aberrantes.")
        
        # Pipeline pour variables qualitatives
        st.markdown("### Pipeline de traitement des variables qualitatives")
        if st.button("Pipeline de traitement des variables qualitatives"):
            qual_vars = df.select_dtypes(include="object").columns
            if not qual_vars.empty:
                method = st.selectbox("Choisissez la m√©thode d'imputation des valeurs manquantes :", ["Mode", "Exclure la variable"])
                
                if method == "Mode":
                    for col in qual_vars:
                        missing_rate = missing_percent[col]
                        if missing_rate < 10:
                            df[col].fillna(df[col].mode()[0], inplace=True)
                        else:
                            df.drop(columns=[col], inplace=True)
                elif method == "Exclure la variable":
                    for col in qual_vars:
                        missing_rate = missing_percent[col]
                        if missing_rate >= 10:
                            df.drop(columns=[col], inplace=True)
                st.success("Pipeline pour variables qualitatives ex√©cut√© avec succ√®s.")
            else:
                st.info("Aucune variable qualitative d√©tect√©e.")

        # Pipeline pour variables quantitatives
        st.markdown("### Pipeline de traitement des variables quantitatives")
        if st.button("Pipeline de traitement des variables quantitatives"):
            quant_vars = df.select_dtypes(exclude="object").columns
            if not quant_vars.empty:
                method = st.selectbox("Choisissez la m√©thode d'imputation des valeurs manquantes :", ["M√©diane", "Moyenne"])
                
                if method == "M√©diane":
                    for col in quant_vars:
                        missing_rate = missing_percent[col]
                        if missing_rate < 10:
                            df[col].fillna(df[col].median(), inplace=True)
                        else:
                            df.drop(columns=[col], inplace=True)
                elif method == "Moyenne":
                    for col in quant_vars:
                        missing_rate = missing_percent[col]
                        if missing_rate < 10:
                            df[col].fillna(df[col].mean(), inplace=True)
                        else:
                            df.drop(columns=[col], inplace=True)
                st.success("Pipeline pour variables quantitatives ex√©cut√© avec succ√®s.")
            else:
                st.info("Aucune variable quantitative d√©tect√©e.")
        
        # Stockage de la base unifi√©e
        st.session_state.processed_data = df
        st.success("La base unifi√©e apr√®s traitement a √©t√© stock√©e avec succ√®s pour la visualisation.")
    else:
        st.warning("Veuillez d'abord importer les donn√©es.")


# Page de visualisation
# Page de visualisation
def visualization_page():
    st.title("Visualisation des donn√©es")
    if st.session_state.get("processed_data") is not None:
        df = st.session_state.processed_data

        st.markdown("**1. Aper√ßu des donn√©es trait√©es**")
        st.write("Apr√®s le traitement des donn√©es, le jeu de donn√©es contient :", df.shape[0], "lignes et", df.shape[1], "colonnes.")
        st.write("Analyses descriptives des variables quantitatives apr√®s traitement", df.describe())

        # S√©paration des variables quantitatives et qualitatives
        quant_vars = df.select_dtypes(include=["int64", "float64"]).columns
        qual_vars = df.select_dtypes(include=["object", "category"]).columns
        # Multiselect pour choisir les variables quantitatives
        st.markdown("**2. Graphique de corr√©lations**")
        selected_quant_vars = st.multiselect("S√©lectionnez les variables quantitatives pour la heatmap :", quant_vars)

        if selected_quant_vars:
            # Calcul de la matrice de corr√©lation de Spearman
            corr = df[selected_quant_vars].corr(method="spearman")
            # Masque pour la partie sup√©rieure de la matrice
            mask = np.zeros_like(corr)
            mask[np.triu_indices_from(mask)] = True
            # Cr√©ation de la heatmap
            plt.figure(figsize=(10, 7))
            sns.heatmap(corr, cmap='Blues', annot=True, square=True, fmt='.3f',
                        mask=mask, cbar=True, vmin=-1, vmax=1)
            # Affichage dans Streamlit
            st.pyplot(plt)

        # Choix de la variable √† visualiser
        st.markdown("**3. Repr√©sentation graphique de toutes les variables**")
        var_type = st.radio("Choisissez le type de variable √† visualiser :", ["Quantitative", "Qualitative"])
        if var_type == "Quantitative":
            selected_quant_var = st.selectbox("S√©lectionnez une variable quantitative :", quant_vars)
            if selected_quant_var:
                plot_type = st.radio("Choisissez un type de graphique :", ["Box Plot", "Histogramme"])
                if plot_type == "Histogramme":
                    bins = st.slider("Nombre de bins pour l'histogramme :", 5, 50, 10)
                    fig = px.histogram(df, x=selected_quant_var, nbins=bins, title=f"Histogramme de {selected_quant_var}")
                    fig.update_traces(marker=dict(line=dict(width=1, color="black")))  # L√©g√®re bordure des barres
                    fig.update_layout(bargap=0.2)  # Espacement entre les barres
                    st.plotly_chart(fig)
                elif plot_type == "Box Plot":
                    fig = px.box(df, y=selected_quant_var, title=f"Box Plot de {selected_quant_var}")
                    st.plotly_chart(fig)

        elif var_type == "Qualitative":
            selected_qual_var = st.selectbox("S√©lectionnez une variable qualitative :", qual_vars)
            if selected_qual_var:
                modality_count = df[selected_qual_var].nunique()
                if modality_count == 2:
                    plot_type = st.radio("Choisissez un type de graphique :", ["Camembert", "Graphique en Anneau"])
                    counts = df[selected_qual_var].value_counts(normalize=True) * 100  # Proportions en pourcentages
                    if plot_type == "Camembert":
                        fig = px.pie(df, names=counts.index, values=counts.values, title=f"R√©partition de {selected_qual_var}")
                        st.plotly_chart(fig)
                    elif plot_type == "Graphique en Anneau":
                        fig = px.pie(df, names=counts.index, values=counts.values, title=f"R√©partition de {selected_qual_var}", hole=0.4)
                        st.plotly_chart(fig)
                else:
                    # Barplot pour les variables √† plusieurs modalit√©s
                    counts = df[selected_qual_var].value_counts(normalize=True) * 100  # Proportions en pourcentages
                    fig = px.bar(x=counts.index, y=counts.values, color=counts.index,
                                 labels={"x": selected_qual_var, "y": "Pourcentage"},
                                 title=f"Barplot de {selected_qual_var}")
                    st.plotly_chart(fig)

        # Apr√®s les autres graphiques (ajout en bas de la page de visualisation)
        st.markdown("**4. Nuage de points**")
        # S√©lection des variables quantitatives √† comparer
        quant_vars = df.select_dtypes(include=["int64", "float64"]).columns
        var_x = st.selectbox("S√©lectionnez la variable sur l'axe X :", quant_vars)
        var_y = st.selectbox("S√©lectionnez la variable sur l'axe Y :", quant_vars)

        # Si les deux variables sont s√©lectionn√©es, afficher le nuage de points avec la droite de r√©gression
        if var_x and var_y:
            # Option pour colorier en fonction d'une variable cat√©gorielle
            qual_vars = df.select_dtypes(include=["object", "category"]).columns
            color_var = st.selectbox("Choisissez une variable cat√©gorielle pour colorier le nuage de points (optionnel) :", qual_vars.tolist() + ["Aucune"])

            # Cr√©er le nuage de points avec Plotly
            if color_var == "Aucune":
                fig = px.scatter(df, x=var_x, y=var_y, title=f"Nuage de points de {var_x} vs {var_y}",
                                trendline="ols", labels={var_x: var_x, var_y: var_y})
            else:
                fig = px.scatter(df, x=var_x, y=var_y, color=color_var, title=f"Nuage de points de {var_x} vs {var_y} par {color_var}",
                                 labels={var_x: var_x, var_y: var_y, color_var: color_var})
            
            # Afficher le graphique dans Streamlit
            st.plotly_chart(fig)

    else:
        st.warning("Veuillez passer par l'√©tape de traitement des donn√©es avant de les visualiser.")


import joblib  # Pour sauvegarder et charger les mod√®les
import os

best_model_pipeline = None
best_model_name = None
best_model_params = None

def modeling_page():
    global best_model_pipeline, best_model_name, best_model_params

    st.title("Mod√©lisation")
    st.subheader("1. Choix des variables, partition des donn√©es et r√©sultats")
    
    if st.session_state.get("processed_data") is not None:
        df = st.session_state.processed_data
        # S√©lection des variables
        target = st.selectbox("S√©lectionnez la variable cible :", df.columns)
        features = st.multiselect("S√©lectionnez les variables explicatives :", df.columns)
        test_size = st.slider("Pourcentage des donn√©es de test :", 10, 50, 20) / 100

        if st.button("Ex√©cuter les mod√®les"):
            X = df[features]
            y = df[target]

            # Traitement des variables cat√©gorielles
            cat_vars = X.select_dtypes(include="object").columns
            num_vars = X.select_dtypes(exclude="object").columns

            # Mise en place du pr√©processeur avec imputation
            preprocessor = ColumnTransformer(
                transformers=[
                    # Imputation par la m√©diane et standardisation pour les variables num√©riques
                    ("num", Pipeline([
                        ("imputer", SimpleImputer(strategy="median")),
                        ("scaler", StandardScaler())
                    ]), num_vars),
                    
                    # Imputation par le mode et encodage one-hot pour les variables cat√©gorielles
                    ("cat", Pipeline([
                        ("imputer", SimpleImputer(strategy="most_frequent")),
                        ("onehot", OneHotEncoder(handle_unknown="ignore"))
                    ]), cat_vars),
                ]
            )

            # Split des donn√©es
            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=42)

            results = []
            pipelines = {}

            # Mod√©lisation avec tous les mod√®les
            for name, (model, params) in MODELS_WITH_PARAMS.items():
                pipeline = Pipeline(steps=[("preprocessor", preprocessor), ("model", model)])
                pipeline.fit(X_train, y_train)
                y_pred = pipeline.predict(X_test)
                mse = mean_squared_error(y_test, y_pred)
                r2 = r2_score(y_test, y_pred)
                adj_r2 = 1 - (1 - r2) * (len(y_test) - 1) / (len(y_test) - len(features) - 1)
                results.append({"Model": name, "MSE": mse, "R2": r2, "Adj R2": adj_r2})
                pipelines[name] = pipeline

            results_df = pd.DataFrame(results).sort_values(by=["R2", "MSE", "Adj R2"], ascending=[False, True, False])
            st.markdown("R√©sultats des mod√®les :")
            st.table(results_df)

            # S√©lection du meilleur mod√®le
            best_model_name = results_df.iloc[0]["Model"]
            best_model_pipeline = pipelines[best_model_name]
            st.write(f"Meilleur mod√®le : {best_model_name}")

            # Validation crois√©e
            st.subheader("2. Validation crois√©e")
            cross_val_scores = cross_val_score(best_model_pipeline, X, y, cv=5, scoring="r2")
            
            # Cr√©er un DataFrame avec les num√©ros des scores et les valeurs correspondantes
            scores_df = pd.DataFrame({
                "Score": [f"Score {i+1}" for i in range(len(cross_val_scores))],
                "R2 Value": cross_val_scores
            })

            # Cr√©er un histogramme avec Plotly
            fig = px.bar(
                scores_df,
                x="Score",  # Les labels des scores (Score 1, Score 2, etc.)
                y="R2 Value",  # Les valeurs des scores R2
                title="Scores R2 par Validation Crois√©e",
                labels={"Score": "Score", "R2 Value": "Valeur du Score R2"},
            )

            # Mettre √† jour la mise en page
            fig.update_layout(
                xaxis_title="Scores",
                yaxis_title="Valeur R2",
                showlegend=False
            )

            # Afficher le graphique dans Streamlit
            st.plotly_chart(fig)
            st.write("Moyenne des scores R2 :", np.mean(cross_val_scores))

            # Optimisation des hyperparam√®tres
            st.subheader("3. Optimisation des hyperparam√®tres")
            model, params = MODELS_WITH_PARAMS[best_model_name]
            grid_search = GridSearchCV(
                estimator=Pipeline(steps=[("preprocessor", preprocessor), ("model", model)]),
                param_grid=params,
                cv=5,
                scoring="r2",
            )
            grid_search.fit(X, y)
            best_model_params = grid_search.best_params_
            st.write("Meilleurs param√®tres :", best_model_params)

            # Sauvegarder le meilleur mod√®le et ses param√®tres
            #st.write("Sauvegarde du meilleur mod√®le...")
            model_filename = "best_model_pipeline.pkl"
            params_filename = "best_model_params.pkl"

            # Mise √† jour des variables globales
            best_model_pipeline = best_model_pipeline
            best_model_name     = best_model_name
            best_model_params   = grid_search.best_params_
            
            # Sauvegarde du pipeline et des param√®tres
            joblib.dump(best_model_pipeline, model_filename)
            joblib.dump(best_model_params, params_filename)

            
            #st.write(f"Mod√®le sauvegard√© dans '{model_filename}' et param√®tres dans '{params_filename}'.")

            # Courbes d'apprentissage
            st.subheader("4. Courbes d'apprentissage")
            train_sizes, train_scores, test_scores = learning_curve(
                best_model_pipeline, X, y, cv=5, scoring="r2", train_sizes=np.linspace(0.1, 1.0, 10)
            )
            train_scores_mean = np.mean(train_scores, axis=1)
            test_scores_mean = np.mean(test_scores, axis=1)
            train_scores_std = np.std(train_scores, axis=1)  # √âcart type des scores d'entra√Ænement
            test_scores_std = np.std(test_scores, axis=1)  # √âcart type des scores de validation

            # Cr√©ation du graphique
            fig, ax = plt.subplots(figsize=(10, 6))

            # Courbes pour les scores d'entra√Ænement et de validation
            ax.plot(train_sizes, train_scores_mean, 'o-', color="r", label="Score d'entra√Ænement")
            ax.plot(train_sizes, test_scores_mean, 'o-', color="g", label="Score de validation")

            # Zones d'intervalle de confiance (√©cart type)
            ax.fill_between(train_sizes, train_scores_mean - train_scores_std, train_scores_mean + train_scores_std, 
                            alpha=0.1, color="r")
            ax.fill_between(train_sizes, test_scores_mean - test_scores_std, test_scores_mean + test_scores_std, 
                            alpha=0.1, color="g")

            # Titres et labels
            ax.set_title("Courbe d'apprentissage")
            ax.set_xlabel("Taille des donn√©es d'entra√Ænement")
            ax.set_ylabel("Score R2")
            ax.legend(loc="best")

            # Affichage dans Streamlit
            st.pyplot(fig)

# Page de pr√©diction mise √† jour
import pandas as pd
import streamlit as st

# Page de pr√©diction
def prediction_page(shared_data):
    st.title("Pr√©diction")

    # R√©cup√©ration des donn√©es partag√©es
    best_model_pipeline = shared_data.get("best_model_pipeline")
    best_model_name = shared_data.get("best_model_name")
    best_model_params = shared_data.get("best_model_params")
    df = shared_data.get("df")

    # V√©rification de l'√©tat de la mod√©lisation
    if best_model_pipeline is None:
        st.warning("Veuillez d'abord ex√©cuter la mod√©lisation pour choisir un mod√®le.")
        return

    # Affichage des informations du mod√®le
    st.write(f"**Meilleur mod√®le** : {best_model_name}")
    st.write("**Meilleurs param√®tres** :", best_model_params)

    # Identification des types de variables
    if df is not None:
        categorical_features = df.select_dtypes(include="object").columns.tolist()
        numerical_features = df.select_dtypes(exclude="object").columns.tolist()
    else:
        st.error("Les donn√©es ne sont pas disponibles. Veuillez v√©rifier la page de pr√©traitement.")
        return

    # Initialisation du dictionnaire pour les entr√©es utilisateur
    inputs = {}

    # Cr√©ation des widgets pour les variables cat√©gorielles
    st.subheader("Entrez les valeurs pour les variables")
    st.write("### Variables cat√©gorielles")
    for col in categorical_features:
        unique_values = df[col].dropna().unique()
        inputs[col] = st.selectbox(f"{col} :", options=unique_values)

    # Cr√©ation des widgets pour les variables num√©riques
    st.write("### Variables num√©riques")
    for col in numerical_features:
        default_value = round(df[col].mean(), 2) if df[col].dtype in ['float64', 'int64'] else 0.0
        inputs[col] = st.number_input(f"{col} :", value=default_value)

    # Bouton pour effectuer la pr√©diction
    if st.button("Pr√©dire"):
        try:
            # Conversion des entr√©es en DataFrame
            input_data = pd.DataFrame([inputs])

            # Assurer la coh√©rence des types de donn√©es
            input_data[numerical_features] = input_data[numerical_features].apply(pd.to_numeric, errors='coerce')
            input_data[categorical_features] = input_data[categorical_features].astype(str)

            # V√©rification des valeurs invalides
            if input_data.isnull().any().any():
                st.error("Certaines entr√©es contiennent des valeurs invalides. Veuillez corriger les donn√©es.")
                return

            # Faire la pr√©diction
            try:
                # Ex√©cution de la pr√©diction
                prediction = best_model_pipeline.predict(input_data)
                st.success(f"Pr√©diction : {prediction[0]}")
            except ValueError as ve:
                st.error(f"Erreur de validation des donn√©es : {ve}")
            except Exception as e:
                st.error(f"Erreur inattendue : {e}")

            # Affichage des probabilit√©s si applicable
            model = best_model_pipeline.named_steps.get("model")
            if model and hasattr(model, "predict_proba"):
                probabilities = model.predict_proba(input_data)
                st.write("### Probabilit√©s par classe")
                st.write(probabilities)

        except Exception as e:
            st.error(f"Une erreur est survenue lors de la pr√©diction : {e}")
            
# Structure de l'application

# CSS rapide pour le style de la sidebar
# CSS pour styliser le panneau lat√©ral
st.markdown(
    """
    <style>
    /* Personnalisation du panneau lat√©ral */
    [data-testid="stSidebar"] {
        background-color: #1A1947; /* Couleur bleu fonc√© */
        color: white;
        padding: 10px;
    }

    /* Police et style pour tout texte dans le panneau lat√©ral */
    [data-testid="stSidebar"] * {
        color: white; /* Couleur du texte */
        font-size: 16px; /* Taille de la police */
    }

    /* Police et style pour les titres */
    [data-testid="stSidebar"] h1, 
    [data-testid="stSidebar"] h2, 
    [data-testid="stSidebar"] h3 {
        color: white;
        font-weight: bold;
    }

    /* Style des liens et navigation */
    [data-testid="stSidebar"] a {
        color: white;
        text-decoration: none;
        font-size: 16px;
    }

    /* Ic√¥nes ou emojis avec texte */
    .sidebar-item {
        display: flex;
        align-items: center;
        gap: 10px;
        margin-bottom: 15px;
    }

    /* √âl√©ments s√©lectionn√©s */
    [data-testid="stSidebar"] .css-1l02zno { 
        font-weight: bold;
        color: white; /* Garder les √©l√©ments s√©lectionn√©s en blanc */
    }
    </style>
    """,
    unsafe_allow_html=True,
)



PAGES = {
    "üìä Pr√©sentation de donn√©es": preprocessing_page,
    "üîß Traitement de donn√©es": missing_values_page,
    "üìà Data visualisation": visualization_page,
    "ü§ñ Mod√©lisation": modeling_page,
    "üéØ Pr√©diction": lambda: prediction_page(shared_data),
}

def main():
    st.sidebar.title("Machine Learning")
    page = st.sidebar.radio("Pages", list(PAGES.keys()))
    PAGES[page]()

if __name__ == "__main__":
    # Dictionnaire partag√© pour centraliser les donn√©es
    shared_data = {
        "df": None,  # DataFrame principal
        "best_model_pipeline": None,
        "best_model_name": None,
        "best_model_params": None,
    }
    main()